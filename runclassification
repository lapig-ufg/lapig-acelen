//Import functions
var func = require('users/Amazonas21/acelen:functions')

//Create globals variables
var trainSamples_main,extra_samples

//Function to classification pastures
var run_classficiation = function(carta, year){

    //var nm_carta = carta; //Changes the chart variable name

    //var cartas_area = cartas.filter(ee.Filter.eq('grid_name', nm_carta)) // Filters the main charts feature collection by the choosed chart
    //var cartas_buffer = cartas_area.geometry().buffer(100000) // Selects the charts around the choosed chart

    var START_DATE = year - 1+"-07-01" //Start date to filter the image collection (usually six months before the main year)
    var END_DATE = year + 1+"-06-30" //End date to filter the image collection (usually six months after the main year)

    var s2 = (ee.ImageCollection("COPERNICUS/S2_HARMONIZED") //Selects the Sentinel 2 TOA Harmonized time series 
        .filterBounds(cartas_buffer) //Filters the images that intersects with the main and neighbor charts
        .filterDate(START_DATE, END_DATE) //Filters the images by the range of dates (start and end)
    )

    var csPlus = (ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED') //Selects the Google Sentinel 2 AI Cloud Score +, the best cloud and shadow mask from Sentinel 2
        .filterBounds(cartas_buffer) //Filters the images that intersects with the main and neighbor charts
        .filterDate(START_DATE, END_DATE)); //Filters the images by the range of dates (start and end)

    var csPlusBands = csPlus.first().bandNames(); //Get the band names of the Cloud Score+ bands

    var s2CloudMasked = (s2.linkCollection(csPlus, csPlusBands) //Link the Sentinel collection with the CloudScore+
        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', 80)) //Filter the images with more than 80% of cloud
        .map(func.maskEdges) //Applies the filter to mask fault edges
        .map(func.maskClouds) //Applies the filter to mask cloud and shadows
        .map(func.res_bilinear)); //Applies the bilinear resampling on the lower resolution images (i.e. 20 meters)
    
    //Applies the spectral index calculations and selects the bands to be used
    var spectralDataNei = s2CloudMasked.map(func.spectralFeatures)
        .select(['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A',
            'B11', 'B12', 'NDVI', 'NDWI', 'CAI', 'CRI1', 'ARI_1', 'RGR',
            'PSRI', 'SATVI'
        ])
        

    //Calculates the 25% NDVI percentile to use as a noise mask
    var wetThresholdNei = spectralDataNei.select("NDVI").reduce(ee.Reducer.percentile([25]))
        
    //Function made to get the image NDVI and mask it according to the 25% NDVI percentile
    var onlyWetSeasonNei = function(image){
        seasonMask = image.select("ndvi_wet").gte(wetThresholdNei);
        return image.mask(seasonMask);
    }
    //Applies the 25% NDVI percentile mask to each image in the collection
    var wetSpectralDataNei = (spectralDataNei
        .select(spectralDataNei.first().bandNames(), BandsWet)
        .map(onlyWetSeasonNei));
    
    //Applies the functions to calculate percentiles, get latitude and longitude, calculate the temporal reducers and adds the elevation and slope data.
    var temporalData = (func.getLatLong(func.temporalPercs(wetSpectralDataNei))
      .addBands([func.temporalFeatures(wetSpectralDataNei),elevation, slope]));

    var featureSpace = ee.Image(temporalData)
        
    //Defines the name of the column to be used as training reference (e.g. cons_2022); NEEDS TO BE INTERGER DATA (i.e. 1 ,2 ,3 4)
    var classFieldName = 'cons_'+ year;
    
    //Function made to adjust the class field from the extra training samples 
    var make_classFieldName = function(feat){
        return feat.set(classFieldName, feat.get('is_pasture'));
    }
    
    //Merges the main training samples with the extra training samples
    trainSamples_main = ee.FeatureCollection('users/vieiramesquita/LAPIG-PASTURE/VECTORS/mapa_pastagem_col8_50k_final_v2')

    if (year < 2023){
      trainSamples_main = ee.FeatureCollection(trainSamples_main).select(classFieldName)
    }else{
      classFieldName = 'cons_2022'
      trainSamples_main = ee.FeatureCollection(trainSamples_main).select('cons_2022')
    }
    extra_samples = (ee.FeatureCollection('users/vieiramesquita/LAPIG-PASTURE/VECTORS/Pasture_Extra_Brasil_plus_Date_v1_3')
      .filter(ee.Filter.lte('YearPastur',year)))

    reclass_extra_samples = extra_samples.map(make_classFieldName).select(classFieldName)

    trainSamples = trainSamples_main.merge(reclass_extra_samples)
    
    //Creates and define the classifier parameters (NUmber of Trees, Variables per Split, Minimum Leaf Population, Bag Fraction, Max nodes and Seed)
    classifier = ee.Classifier.smileRandomForest(rfNTrees, rfVarPersplit, 1, rfBagFraction, None, year);

    //Sets the classifier to the Probability Mode - Default is CLASSIFICATION
    classifier = classifier.setOutputMode('PROBABILITY');
    
    //Crosses the training samples with the feature space variables to associate the information with the classes
    trainSamplesFeeded = (featureSpace.sampleRegions(**{
        'collection': trainSamples.filterBounds(cartas_buffer).filter(ee.Filter.neq(classFieldName, None)),
        'properties': [classFieldName],
        'scale': 10,
        'tileScale': 16
    }));
    
    //Trains the classifier using the training samples asociated with the feature space information
    classifier = classifier.train(trainSamplesFeeded, classFieldName);
   
    //Takes the trained classifier and use it to classify the entire feature space pixel by pixel
    classification = featureSpace.classify(classifier).select(0)
  
    return classification
}