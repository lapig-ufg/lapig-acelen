//Import functions
var func = require('users/Amazonas21/acelen:functions')
var data = require('users/Amazonas21/acelen:datasets')
var styles = require('users/Amazonas21/acelen:styles')


//Parameters of the random forest algorithm
var rfNTrees = 500; //#Number of random trees - lesser faster, but worst. 100-500 is the optimal;
var rfBagFraction = 0.5; //#Fraction (10^-2%) of variables in the bag - 0.5/50% is the default;
var rfVarPersplit = 13 //#Number of varibales per tree branch - estimated by the square root of the number of variables used in the feature space;

//Function made to convert deegre image to percent
function radians(img) {
    return img.toFloat().multiply(Math.PI).divide(180)
}

//var gppdata = data.datasets['gpp']
var terrain = ee.Algorithms.Terrain(ee.Image("NASA/NASADEM_HGT/001")); //Terrain variables (i.e. elevation, slope, aspect) extraction from the NASADEM 
var elevation = terrain.select('elevation'); //Selection of the elevation band
var slope = (radians(terrain.select('slope'))).expression('b("slope")*100'); //Selection of the slope band and conversion from deegre to percentage

//List of names to rename the bands
var BandsWet = ['blue_wet', 'green_wet', 'red_wet', 'rededge1_wet', 'rededge2_wet', 'rededge3_wet',
    'nir_wet', 'rededge4_wet', 'swir1_wet', 'swir2_wet', 'ndvi_wet', 'ndwi_wet', 'cai_wet',
    'cri1_wet', 'ari1_wet', 'rgr_wet', 'psri_wet', 'satvi_wet'
];

//Creating automated smaples
//var samplesautomated = func.automatedSamples(imgs,type,year,area,numberSamples,scale)

//########################################

//Main function, responsible to execute the classification. Accept as parameters the chart name (e.g. 'SE-22-X-A') and the year (e.g. 2022)
function run_classfication(carta, year,samples,target) {

    //var nm_carta = carta; //Changes the chart variable name
    
    var cartas_area = carta//cartas.filter(ee.Filter.eq('grid_name', nm_carta)); // Filters the main charts feature collection by the choosed chart
    var cartas_buffer = cartas_area.geometry().buffer(5000); // Selects the charts around the choosed chart

    //OK
    var START_DATE = ee.Date(year+'-01-01')//ee.Date((year - 1) + '-07-01'); //Start date to filter the image collection (usually six months before the main year)
    var END_DATE = ee.Date(year+'-12-31')//ee.Date((year + 1) + '-06-30'); //End date to filter the image collection (usually six months after the main year)

    //OK
    var s2 = ee.ImageCollection("COPERNICUS/S2_HARMONIZED") //Selects the Sentinel 2 TOA Harmonized time series 
        .filterBounds(cartas_buffer) //Filters the images that intersects with the main and neighbor charts
        .filterDate(START_DATE, END_DATE) //Filters the images by the range of dates (start and end)

    //OK
    var csPlus = (ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED') //Selects the Google Sentinel 2 AI Cloud Score +, the best cloud and shadow mask from Sentinel 2
        .filterBounds(cartas_buffer) //Filters the images that intersects with the main and neighbor charts
        .filterDate(START_DATE, END_DATE)); //Filters the images by the range of dates (start and end)

    //OK
    var csPlusBands = csPlus.first().bandNames(); //Get the band names of the Cloud Score+ bands

    //OK
    var s2CloudMasked = (s2.linkCollection(csPlus, csPlusBands) //Link the Sentinel collection with the CloudScore+
        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', 80)) //Filter the images with more than 80% of cloud
        .map(func.maskEdges) //Applies the filter to mask fault edges
        .map(func.maskClouds) //Applies the filter to mask cloud and shadows
        .map(func.res_bilinear)); //Applies the bilinear resampling on the lower resolution images (i.e. 20 meters)
    
    //OK - Applies the spectral index calculations and selects the bands to be used
    var spectralDataNei = (s2CloudMasked
        .map(func.spectralFeatures)
        .select(['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A',
            'B11', 'B12', 'NDVI', 'NDWI', 'CAI', 'CRI1', 'ARI_1', 'RGR',
            'PSRI', 'SATVI'
        ]));
    
    //OK - Calculates the 25% NDVI percentile to use as a noise mask
    var wetThresholdNei = (spectralDataNei
        .select("NDVI")
        .reduce(ee.Reducer.percentile([25])));
    
    
    //OK - Function made to get the image NDVI and mask it according to the 25% NDVI percentile
    function onlyWetSeasonNei(image){
        var seasonMask = image.select("ndvi_wet").gte(wetThresholdNei);
        return image.mask(seasonMask);
    }
        
    //OK - Applies the 25% NDVI percentile mask to each image in the collection
    var wetSpectralDataNei = (spectralDataNei
        .select(spectralDataNei.first().bandNames(), BandsWet)
        .map(onlyWetSeasonNei));
    
    //OK - Applies the functions to calculate percentiles, get latitude and longitude, calculate the temporal reducers and adds the elevation and slope data.
    var temporalData = func.getLatLong(func.temporalPercs(wetSpectralDataNei))
      .addBands([func.temporalFeatures(wetSpectralDataNei),elevation, slope]);
    
    //OK
    var featureSpace = ee.Image(temporalData)

    //OK - Defines the name of the column to be used as training reference (e.g. cons_2022); NEEDS TO BE INTERGER DATA (i.e. 1 ,2 ,3 4)
    var classFieldName = 'cons_' + year;
    
    //Samples to train
    var trainSamples = samples
    
    //Creates and define the classifier parameters (NUmber of Trees, Variables per Split, Minimum Leaf Population, Bag Fraction, Max nodes and Seed)
    var classifier = ee.Classifier.smileRandomForest(rfNTrees, rfVarPersplit, 1, rfBagFraction, null, year);

    //Sets the classifier to the Probability Mode - Default is CLASSIFICATION
    classifier = classifier.setOutputMode('PROBABILITY');
    
    
    //Crosses the training samples with the feature space variables to associate the information with the classes
    var trainSamplesFeeded = (featureSpace.sampleRegions({
        collection: trainSamples,//.filterBounds(cartas_buffer).filter(ee.Filter.neq(classFieldName, null)),
        properties: [target],//[classFieldName],
        scale: 20,
        tileScale: 16,
        
    }));
    
    
    //Trains the classifier using the training samples asociated with the feature space information
    classifier = classifier.train(trainSamplesFeeded, target);//classFieldName);
    
    //Visualization Feature Importance
    print(func.calcFeatureImportance(classifier))
    
    //Takes the trained classifier and use it to classify the entire feature space pixel by pixel
    var classification = featureSpace.classify(classifier).select(0);
        classification = classification.gte(0.51).selfMask().clip(cartas_area)
    //var fileName = 'br_pasture_s2_col2_v1_' + carta + '_' + year; //Output file name
    
    //Map.centerObject(cartas_area,15)
    //Map.addLayer(featureSpace.clip(cartas_buffer),{bands:['ndvi_wet_p90','ndvi_wet_median','ndvi_wet_p10'],min:0.2,max:0.8},
    //  'NDVI Perc Composition (90,50,10)')
    //Map.addLayer(classification.clip(cartas_area),{min:0,max:1},'Classification')
    //Map.addLayer(classification.clip(cartas_buffer),{min:1,max:1,palette:['gold']},'Classification')
    //Map.centerObject(cartas_buffer)
    
    return {'classification':classification}
    /*
    //Generates the export task for the Google Drive
    Export.image.toDrive({
        //Points to the classification image and convert it from Float (0 to 1) to Integer image (0 to 10000) and clips it based on the chart geometry
        image: classification.multiply(10000).int16().clip(cartas_area), 
        crs: "EPSG:4326", //Defines the output porjection
        region: cartas_area.geometry().bounds(), //Defines the output porjection
        description: fileName, //Gets the output file name
        folder: my_folder, //Gets the output folder name
        scale: 10, //Sets the output resolution, measured in meters
        maxPixels: 1e13, //Sets the maximum amount of pixels that can be exported, which is 10^13 or 1E13
    });
    */
}

// ##############CHECK#################
exports.getRun = function(typegrass,year,farm,maplayer){
  //Classification Params
  var year = year
  
  //Automated Params - New
  var type = {'Cultivada':'cultivated'}
      type = type[typegrass]
  
  var farm = farm
  var area = data.datasets['test_data'].filter(ee.Filter.eq('Fazenda',farm))
  var imgs = data.datasets[type+"_perc"].toBands()
  var numberSamples = 500
  var scale = 10
  
  
  var gppdata = data.datasets['gpp']
  
  //Creating automated smaples
  var samplesautomated = func.automatedSamples(imgs,type,year,area,numberSamples,scale)
  
  //Run classification and GPP
  var classRF = run_classfication(area,year,samplesautomated['samples'],'targetMap')
  var trendgpp = func.trendgpp(gppdata,2007,2021,classRF['classification'])
  
  //Add layers in map
  maplayer.addLayer(trendgpp['initial-gpp'],styles.gpp,'GPP-Initial')
  maplayer.addLayer(classRF['classification'],{min:1,max:1,palette:['gold']},'Classification')
  maplayer.addLayer(area,{},'Propriedade')
  maplayer.centerObject(area)
}


//Executes the classification function
//run_classficiation(IBGE_CHART, year);
//var classRF = run_classfication(area,year,samplesautomated['samples'],'targetMap')
//var trendgpp = func.trendgpp(gppdata,2007,2021,classRF['classification'])

//Map.addLayer(trendgpp['initial-gpp'],{},'GPP-Initial')
//Map.addLayer(classRF['classification'],{min:1,max:1,palette:['gold']},'Classification')
//Map.addLayer(trendgpp['initial-gpp'],{},'GPP-Initial')
//Map.addLayer(trendgpp['final-gpp'],{},'GPP-Final')
//Map.addLayer(area,{},'Propriedade')
