//Import functions
var func = require('users/Amazonas21/acelen:functions')
var data = require('users/Amazonas21/acelen:datasets')

//Classification Params
var year = 2001
var IBGE_CHART = 'SE-22-X-A' //Check here the code of the desired IBGE Chart
var my_folder = 'lapig_br_pasture_mapping_s2_v1'

//Automated Params - New
var type = 'cultivated'
var area = data.datasets['test_data'].filter(ee.Filter.eq('Fazenda','ADRIANA'))
var imgs = data.datasets[type+"_perc"].toBands()
var numberSamples = 500
var scale = 30


//Charts used as region/model delimitation
var cartas = ee.FeatureCollection(
    "users/vieiramesquita/LAPIG-PASTURE/VECTORS/CARTAS_IBGE_BR_mod"
)

var rfNTrees = 500; //#Number of random trees - lesser faster, but worst. 100-500 is the optimal;
var rfBagFraction = 0.5; //#Fraction (10^-2%) of variables in the bag - 0.5/50% is the default;
var rfVarPersplit = 13 //#Number of varibales per tree branch - estimated by the square root of the number of variables used in the feature space;

//Function made to convert deegre image to percent
function radians(img) {
    return img.toFloat().multiply(Math.PI).divide(180)
}


var terrain = ee.Algorithms.Terrain(ee.Image("NASA/NASADEM_HGT/001")); //Terrain variables (i.e. elevation, slope, aspect) extraction from the NASADEM 
var elevation = terrain.select('elevation'); //Selection of the elevation band
var slope = (radians(terrain.select('slope'))).expression('b("slope")*100'); //Selection of the slope band and conversion from deegre to percentage

//List of names to rename the bands
var BandsWet = ['blue_wet', 'green_wet', 'red_wet', 'rededge1_wet', 'rededge2_wet', 'rededge3_wet',
    'nir_wet', 'rededge4_wet', 'swir1_wet', 'swir2_wet', 'ndvi_wet', 'ndwi_wet', 'cai_wet',
    'cri1_wet', 'ari1_wet', 'rgr_wet', 'psri_wet', 'satvi_wet'
];

//List of names to rename amplitude bands
var BandsWetAmp = ['blue_wet_amp', 'green_wet_amp', 'red_wet_amp', 'rededge1_wet_amp',
    'rededge2_wet_amp', 'rededge3_wet_amp', 'nir_wet_amp', 'rededge4_wet_amp', 'swir1_wet_amp', 'swir2_wet_amp',
    'ndvi_wet_amp', 'ndwi_wet_amp', 'cai_wet_amp', 'cri1_wet_amp', 'ari1_wet_amp', 'rgr_wet_amp',
    'psri_wet_amp', 'satvi_wet_amp'
];

var samplesautomated = func.automatedSamples(imgs,type,year,area,numberSamples,scale)

Map.centerObject(samplesautomated['samples'])
Map.addLayer(samplesautomated['target-data'],{palette:['red','green']},'Samples - Image')
Map.addLayer(samplesautomated['samples'],{},'Amostras:'+year)
//########################################

//Main function, responsible to execute the classification. Accept as parameters the chart name (e.g. 'SE-22-X-A') and the year (e.g. 2022)
function run_classfication(carta, year,samples,target) {

    //var nm_carta = carta; //Changes the chart variable name

    var cartas_area = carta//cartas.filter(ee.Filter.eq('grid_name', nm_carta)); // Filters the main charts feature collection by the choosed chart
    var cartas_buffer = cartas_area.geometry().buffer(5000); // Selects the charts around the choosed chart

    //OK
    var START_DATE = ee.Date((year - 1) + '-07-01'); //Start date to filter the image collection (usually six months before the main year)
    var END_DATE = ee.Date((year + 1) + '-06-30'); //End date to filter the image collection (usually six months after the main year)

    //OK
    var s2 = ee.ImageCollection("COPERNICUS/S2_HARMONIZED") //Selects the Sentinel 2 TOA Harmonized time series 
        .filterBounds(cartas_buffer) //Filters the images that intersects with the main and neighbor charts
        .filterDate(START_DATE, END_DATE) //Filters the images by the range of dates (start and end)

    //OK
    var csPlus = (ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED') //Selects the Google Sentinel 2 AI Cloud Score +, the best cloud and shadow mask from Sentinel 2
        .filterBounds(cartas_buffer) //Filters the images that intersects with the main and neighbor charts
        .filterDate(START_DATE, END_DATE)); //Filters the images by the range of dates (start and end)

    //OK
    var csPlusBands = csPlus.first().bandNames(); //Get the band names of the Cloud Score+ bands

    //OK
    var s2CloudMasked = (s2.linkCollection(csPlus, csPlusBands) //Link the Sentinel collection with the CloudScore+
        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', 80)) //Filter the images with more than 80% of cloud
        .map(func.maskEdges) //Applies the filter to mask fault edges
        .map(func.maskClouds) //Applies the filter to mask cloud and shadows
        .map(func.res_bilinear)); //Applies the bilinear resampling on the lower resolution images (i.e. 20 meters)
    
    //OK - Applies the spectral index calculations and selects the bands to be used
    var spectralDataNei = (s2CloudMasked
        .map(func.spectralFeatures)
        .select(['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A',
            'B11', 'B12', 'NDVI', 'NDWI', 'CAI', 'CRI1', 'ARI_1', 'RGR',
            'PSRI', 'SATVI'
        ]));

    //OK - Calculates the 25% NDVI percentile to use as a noise mask
    var wetThresholdNei = (spectralDataNei
        .select("NDVI")
        .reduce(ee.Reducer.percentile([25])));
    
    //OK - Function made to get the image NDVI and mask it according to the 25% NDVI percentile
    function onlyWetSeasonNei(image){
        seasonMask = image.select("ndvi_wet").gte(wetThresholdNei);
        return image.mask(seasonMask);
    }
        
    //OK - Applies the 25% NDVI percentile mask to each image in the collection
    var wetSpectralDataNei = (spectralDataNei
        .select(spectralDataNei.first().bandNames(), BandsWet)
        .map(onlyWetSeasonNei));
    
    //OK - Applies the functions to calculate percentiles, get latitude and longitude, calculate the temporal reducers and adds the elevation and slope data.
    var temporalData = func.getLatLong(func.temporalPercs(wetSpectralDataNei))
      .addBands([func.temporalFeatures(wetSpectralDataNei),elevation, slope]);

    //OK
    var featureSpace = ee.Image(temporalData)

    //OK - Prints the feature space band names
    print(featureSpace.bandNames())
    
    
    //OK - Defines the name of the column to be used as training reference (e.g. cons_2022); NEEDS TO BE INTERGER DATA (i.e. 1 ,2 ,3 4)
    var classFieldName = 'cons_' + year;
    
    //OK - Function made to adjust the class field from the extra training samples 
    function make_classFieldName(feat) {
        return feat.set(classFieldName, feat.get('is_pasture'));
    }
  
    //Merges the main training samples with the extra training samples
    //var trainSamples_main = ee.FeatureCollection('users/vieiramesquita/LAPIG-PASTURE/VECTORS/mapa_pastagem_col8_50k_final_v2')

    //if (year < 2023){
      //trainSamples_main = ee.FeatureCollection(trainSamples_main).select(classFieldName)
    //} else{
    //  classFieldName = 'cons_2022'
    //  trainSamples_main = ee.FeatureCollection(trainSamples_main).select('cons_2022')
    //}
    
    //var extra_samples = (ee.FeatureCollection('users/vieiramesquita/LAPIG-PASTURE/VECTORS/Pasture_Extra_Brasil_plus_Date_v1_3')
    //  .filter(ee.Filter.lte('YearPastur',year)))

    //var reclass_extra_samples = extra_samples.map(make_classFieldName).select(classFieldName)

    var trainSamples = samples//trainSamples_main.merge(reclass_extra_samples)
    
    //Creates and define the classifier parameters (NUmber of Trees, Variables per Split, Minimum Leaf Population, Bag Fraction, Max nodes and Seed)
    var classifier = ee.Classifier.smileRandomForest(rfNTrees, rfVarPersplit, 1, rfBagFraction, null, year);

    //Sets the classifier to the Probability Mode - Default is CLASSIFICATION
    classifier = classifier.setOutputMode('PROBABILITY');
    
    //Crosses the training samples with the feature space variables to associate the information with the classes
    var trainSamplesFeeded = (featureSpace.sampleRegions({
        'collection': trainSamples,//.filterBounds(cartas_buffer).filter(ee.Filter.neq(classFieldName, null)),
        'properties': [target],//[classFieldName],
        'scale': 10,
        'tileScale': 16
    }));
    
    print('Pontos amostradas:',trainSamplesFeeded)
    //Trains the classifier using the training samples asociated with the feature space information
    classifier = classifier.train(trainSamplesFeeded, target);//classFieldName);
    
    //Visualization Feature Importance
    print(func.calcFeatureImportance(classifier))
    
    //Takes the trained classifier and use it to classify the entire feature space pixel by pixel
    var classification = featureSpace.classify(classifier).select(0);
    
    //var fileName = 'br_pasture_s2_col2_v1_' + carta + '_' + year; //Output file name
    
    Map.centerObject(cartas_area,15)
    Map.addLayer(featureSpace.clip(cartas_area),{bands:['ndvi_wet_p90','ndvi_wet_median','ndvi_wet_p10'],min:0.2,max:0.8},
      'NDVI Perc Composition (90,50,10)')
    //Map.addLayer(classification.clip(cartas_area),{min:0,max:1},'Classification')
    Map.addLayer(classification.clip(cartas_area),{min:0,max:1},'Classification')
    Map.centerObject(cartas_area)
    /*
    //Generates the export task for the Google Drive
    Export.image.toDrive({
        //Points to the classification image and convert it from Float (0 to 1) to Integer image (0 to 10000) and clips it based on the chart geometry
        image: classification.multiply(10000).int16().clip(cartas_area), 
        crs: "EPSG:4326", //Defines the output porjection
        region: cartas_area.geometry().bounds(), //Defines the output porjection
        description: fileName, //Gets the output file name
        folder: my_folder, //Gets the output folder name
        scale: 10, //Sets the output resolution, measured in meters
        maxPixels: 1e13, //Sets the maximum amount of pixels that can be exported, which is 10^13 or 1E13
    });
    */
}

// ##############CHECK#################

//Executes the classification function
//run_classficiation(IBGE_CHART, year);
run_classfication(area,year,samplesautomated,'targetMap')
